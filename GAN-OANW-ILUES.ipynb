{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa1bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pprint\n",
    "#from torchsummary import summary\n",
    "from torchinfo import summary\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "import torch.autograd as autograd\n",
    "from torch import optim\n",
    "import pandas as pd\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83882ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matlab.engine\n",
    "eng = matlab.engine.start_matlab('MATLAB_R2021b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f555dfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "    print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "    pass\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7b29f",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c537c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class netG(nn.Module):\n",
    "    def __init__(self, nc = 1, nz = 1, ngf = 64, gfs = 5, ngpu = 1):\n",
    "        super(netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "\n",
    "                nn.ConvTranspose2d(     nz, ngf * 8, gfs, 2, gfs//2, bias=False), \n",
    "                nn.ReLU(True),\n",
    "                nn.InstanceNorm2d(ngf * 8),\n",
    "\n",
    "                nn.ConvTranspose2d(ngf * 8, ngf * 4, gfs, 2, gfs//2, bias=False),\n",
    "                nn.ReLU(True),\n",
    "                nn.InstanceNorm2d(ngf * 4),\n",
    "\n",
    "                nn.ConvTranspose2d(ngf * 4, ngf * 2, gfs, 2, gfs//2, bias=False),\n",
    "                nn.ReLU(True),\n",
    "                nn.InstanceNorm2d(ngf * 2),\n",
    "\n",
    "                nn.ConvTranspose2d(ngf * 2,     ngf, gfs, 2, gfs//2, bias=False),\n",
    "                nn.ReLU(True),\n",
    "                nn.InstanceNorm2d(ngf),\n",
    "               \n",
    "                nn.ConvTranspose2d(    ngf,      nc, 4, 2, 2, bias=False),\n",
    "                nn.ReLU(True),\n",
    "                \n",
    "                ### Start dilations ###\n",
    "                nn.ConvTranspose2d(     nc,ngf, gfs, 1, 6, output_padding=0,bias=False,dilation=3), \n",
    "                nn.ReLU(True),\n",
    "                nn.InstanceNorm2d(ngf),\n",
    "               \n",
    "                nn.ConvTranspose2d(    ngf,  nc, gfs, 1, 10, output_padding=0, bias=False,dilation=5),\n",
    "                \n",
    "                nn.Tanh()\n",
    "                \n",
    "            )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), -1, 5, 5) # (*, 100, 1, 1)\n",
    "        if input.is_cuda and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input,\n",
    "                                               range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57833ca",
   "metadata": {},
   "source": [
    "## import the trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddbf0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = netG().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d086e1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.load_state_dict(torch.load('netG_epoch_27.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6cbb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x19aaaa70848>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = torch.rand(1, 25)*2-1\n",
    "z =noise.cuda()\n",
    "fake = G(z)\n",
    "plt.contourf(fake[0][0].detach().cpu().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23be06",
   "metadata": {},
   "source": [
    "## Getting the N_{e} groups of z and G(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46106cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 100\n",
    "z_dim = 25\n",
    "ngx = 128\n",
    "ngy = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a9fc4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 521 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_Ne = np.zeros((z_dim, Ne))\n",
    "cond_Ne = np.zeros(((ngx * ngy),Ne))\n",
    "for i in range(Ne):\n",
    "    z = torch.rand(1,z_dim)*2-1\n",
    "    output = G.forward(z.cuda())\n",
    "    b1=torch.full(output[0][0].shape, 6).cuda()\n",
    "    b2=torch.full(output[0][0].shape, 2).cuda()\n",
    "    aa = torch.where(output[0] > 0, b1, b2)\n",
    "    a = aa.squeeze().cpu().detach().numpy()\n",
    "    a = a.reshape(128*128,)\n",
    "    z_Ne[:,i] = z.cpu().numpy()\n",
    "    cond_Ne[:,i] = a\n",
    "#scipy.io.savemat('z_Ne.mat', {\"z_Ne\":z_Ne}) \n",
    "scipy.io.savemat('cond_100.mat', {\"cond_Ne\":cond_Ne})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f1b6f",
   "metadata": {},
   "source": [
    "## 获取随机生成结果的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49acc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "z_Ne = np.zeros((z_dim, Ne))\n",
    "list_a=[]\n",
    "list_b=[]\n",
    "for i in range(Ne):\n",
    "    z = torch.rand(1,z_dim)*2-1\n",
    "    output = G.forward(z.cuda())\n",
    "    a = output.squeeze().cpu().detach().numpy()\n",
    "    list1=[]\n",
    "    for i in range(len(a)):\n",
    "        for j in a[i]:\n",
    "            list1.append(j)\n",
    "    a=b=0\n",
    "    for ii in list1:\n",
    "        if ii<0:\n",
    "            a+=1\n",
    "        else:\n",
    "            b+=1\n",
    "    list_a.append(a/16384*100)\n",
    "    list_b.append(b/16384*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c80dc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_b,columns=['channel'])\n",
    "df[\"matrix\"]=list_a\n",
    "df.to_excel(\"generate_faces.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f1730",
   "metadata": {},
   "source": [
    "## import the surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a1f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642bcf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DenseLayer(nn.Sequential):\n",
    "\n",
    "    def __init__(self, in_features, growth_rate, drop_rate=0, bn_size=4, bottleneck=False):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        \n",
    "        if bottleneck and in_features > bn_size * growth_rate:\n",
    "            self.add_module('norm1', nn.BatchNorm2d(in_features))\n",
    "            self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "            \n",
    "            self.add_module('conv1', nn.Conv2d(in_features, bn_size *\n",
    "                            growth_rate, kernel_size=1, stride=1, bias=False))\n",
    "            \n",
    "            self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate))\n",
    "            self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "            \n",
    "            self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                            kernel_size=3, stride=1, padding=1, bias=False))\n",
    "            \n",
    "        else:\n",
    "            self.add_module('norm1', nn.BatchNorm2d(in_features))\n",
    "            self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "            \n",
    "            self.add_module('conv1', nn.Conv2d(in_features, growth_rate, kernel_size=3, stride=1, padding=1, bias=False))\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = super(_DenseLayer, self).forward(x)\n",
    "        if self.drop_rate > 0:\n",
    "            y = F.dropout2d(y, p=self.drop_rate, training=self.training) \n",
    "        z = torch.cat([x, y], 1)\n",
    "        return z\n",
    "class _DenseBlock(nn.Sequential):\n",
    "    def __init__(self, num_layers, in_features, growth_rate, drop_rate, bn_size=4, bottleneck=False):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(in_features + i * growth_rate, growth_rate, drop_rate=drop_rate, bn_size=bn_size, bottleneck=bottleneck)\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "class _Transition(nn.Sequential):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, encoding=True, drop_rate=0., last=False, out_channels=3, outsize_even=True):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(in_features))\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True))\n",
    "        \n",
    "        # encoding\n",
    "        if encoding:\n",
    "            # reduce feature maps; half image size (input feature size is even)\n",
    "            # bottleneck impl, save memory, add nonlinearity\n",
    "            self.add_module('conv1', nn.Conv2d(in_features, out_features, kernel_size=1, stride=1, padding=0, bias=False))\n",
    "            \n",
    "            if drop_rate > 0:\n",
    "                self.add_module('dropout1', nn.Dropout2d(p=drop_rate))\n",
    "            self.add_module('norm2', nn.BatchNorm2d(out_features))\n",
    "            self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "            self.add_module('conv2', nn.Conv2d(out_features, out_features,\n",
    "                                              kernel_size=3, stride=2,\n",
    "                                              padding=1, bias=False))\n",
    "\n",
    "            if drop_rate > 0:\n",
    "                self.add_module('dropout2', nn.Dropout2d(p=drop_rate))\n",
    "        else:\n",
    "            # decoder\n",
    "            if last:\n",
    "                ks = 6 if outsize_even else 3\n",
    "                out_convt = nn.ConvTranspose2d(out_features, out_channels,kernel_size=ks, stride=2,padding=1, bias=False)\n",
    "            else:\n",
    "                out_convt = nn.ConvTranspose2d(out_features, out_features,kernel_size=3, stride=2,padding=1, output_padding=0, bias=False)\n",
    "\n",
    "            # bottleneck impl, save memory, add nonlinearity\n",
    "            self.add_module('conv1', nn.Conv2d(in_features, out_features,kernel_size=1, stride=1,padding=0, bias=False))\n",
    "\n",
    "            if drop_rate > 0:\n",
    "                self.add_module('dropout1', nn.Dropout2d(p=drop_rate))\n",
    "\n",
    "            self.add_module('norm2', nn.BatchNorm2d(out_features))\n",
    "            self.add_module('relu2', nn.ReLU(inplace=True))\n",
    "            self.add_module('convT2', out_convt)\n",
    "            if drop_rate > 0:\n",
    "                self.add_module('dropout2', nn.Dropout2d(p=drop_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b89e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseED(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, blocks, growth_rate=16,\n",
    "                 num_init_features=64, bn_size=4, drop_rate=0, outsize_even=True,\n",
    "                 bottleneck=False):\n",
    "\n",
    "        super(DenseED, self).__init__()\n",
    "\n",
    "        if len(blocks) > 1 and len(blocks) % 2 == 0:\n",
    "            ValueError('length of blocks must be an odd number, but got {}'.format(len(blocks)))\n",
    "            \n",
    "        enc_block_layers = blocks[: len(blocks) // 2]\n",
    "        dec_block_layers = blocks[len(blocks) // 2:]\n",
    "        self.features = nn.Sequential()\n",
    "        self.features.add_module('in_conv',nn.Conv2d(in_channels, num_init_features,kernel_size=7, stride=2, padding=3, bias=False))\n",
    "        #self.features.add_module('in_conv',nn.Conv2d(in_channels, num_init_features,kernel_size=6, stride=2, padding=2, bias=False))\n",
    "\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(enc_block_layers):\n",
    "            block = _DenseBlock(num_layers=num_layers,\n",
    "                                in_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate,\n",
    "                                drop_rate=drop_rate, bottleneck=bottleneck)\n",
    "            self.features.add_module('encblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "\n",
    "            trans = _Transition(in_features=num_features,\n",
    "                                out_features=num_features // 2,\n",
    "                                encoding=True, drop_rate=drop_rate)\n",
    "            self.features.add_module('down%d' % (i + 1), trans)\n",
    "            num_features = num_features // 2\n",
    "\n",
    "        for i, num_layers in enumerate(dec_block_layers):\n",
    "            block = _DenseBlock(num_layers=num_layers,\n",
    "                                in_features=num_features,\n",
    "                                bn_size=bn_size, growth_rate=growth_rate,\n",
    "                                drop_rate=drop_rate, bottleneck=bottleneck)\n",
    "            self.features.add_module('decblock%d' % (i + 1), block)\n",
    "            num_features += num_layers * growth_rate\n",
    "\n",
    "            last_layer = True if i == len(dec_block_layers) - 1 else False\n",
    "\n",
    "            trans = _Transition(in_features=num_features,\n",
    "                                out_features=num_features // 2,\n",
    "                                encoding=False, drop_rate=drop_rate,\n",
    "                                last=last_layer, out_channels=out_channels,\n",
    "                                outsize_even=outsize_even)\n",
    "            self.features.add_module('up%d' % (i + 1), trans)\n",
    "            num_features = num_features // 2\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.features(x)\n",
    "        y[:, 0] = F.softplus(y[:, 0].clone(), beta=1)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def _num_parameters_convlayers(self):\n",
    "        n_params, n_conv_layers = 0, 0\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'conv' in name:\n",
    "                n_conv_layers += 1\n",
    "            n_params += param.numel()\n",
    "        return n_params, n_conv_layers\n",
    "\n",
    "    def _count_parameters(self):\n",
    "        n_params = 0\n",
    "        for name, param in self.named_parameters():\n",
    "            print(name)\n",
    "            print(param.size())\n",
    "            print(param.numel())\n",
    "            n_params += param.numel()\n",
    "            print('num of parameters so far: {}'.format(n_params))\n",
    "\n",
    "    def reset_parameters(self, verbose=False):\n",
    "        for module in self.modules():\n",
    "            # pass self, otherwise infinite loop\n",
    "            if isinstance(module, self.__class__):\n",
    "                continue\n",
    "            if 'reset_parameters' in dir(module):\n",
    "                if callable(module.reset_parameters):\n",
    "                    module.reset_parameters()\n",
    "                    if verbose:\n",
    "                        print(\"Reset parameters in {}\".format(module))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0d93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Dnense Encoder-Decoder Convolutional Network')\n",
    "parser.add_argument('--exp-name', type=str, default='AR-Net', help='experiment name')\n",
    "parser.add_argument('--blocks', type=list, default=(5, 10, 5),\n",
    "                    help='list of number of layers in each block in decoding net')  \n",
    "parser.add_argument('--growth-rate', type=int, default=40, help='output of each conv')  \n",
    "parser.add_argument('--drop-rate', type=float, default=0, help='dropout rate')\n",
    "parser.add_argument('--bn-size', type=int, default=8, help='bottleneck size: bn_size * growth_rate')\n",
    "parser.add_argument('--bottleneck', action='store_true', default=False, help='enable bottleneck in the dense blocks')\n",
    "parser.add_argument('--init-features', type=int, default=48,\n",
    "                    help='# initial features after the first conv layer') \n",
    "\n",
    "parser.add_argument('--data-dir', type=str, default=\"./\", help='data directory')\n",
    "\n",
    "\n",
    "parser.add_argument('--n-train', type=int, default=2000, help=\"number of training data\")\n",
    "parser.add_argument('--n-test', type=int, default=500, help=\"number of test data\")\n",
    "\n",
    "parser.add_argument('--w-c', type=float, default=8.0, help='weight value in the weighted loss')\n",
    "parser.add_argument('--w-c2', type=float, default=4.0, help='weight value in the weighted loss')\n",
    "parser.add_argument('--n-epochs', type=int, default=200, help='number of epochs to train (default: 200)')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='learnign rate')\n",
    "\n",
    "parser.add_argument('--weight-decay', type=float, default=5e-5, help=\"weight decay\")\n",
    "parser.add_argument('--batch-size', type=int, default=16, help='input batch size for training (default: 100)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=32, help='input batch size for testing (default: 100)')\n",
    "parser.add_argument('--log-interval', type=int, default=1,\n",
    "                    help='how many epochs to wait before logging training status')\n",
    "parser.add_argument('--plot-interval', type=int, default=2,\n",
    "                    help='how many epochs to wait before plotting training status')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79559b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseED(3, 2, blocks=args.blocks, growth_rate=args.growth_rate,\n",
    "                        drop_rate=args.drop_rate, bn_size=args.bn_size,\n",
    "                        num_init_features=args.init_features, bottleneck=args.bottleneck).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a41232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./\"\n",
    "model.load_state_dict(torch.load(model_dir + '/model_epoch{}.pth'.format(198)))\n",
    "print('Loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee2374b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simv(y_pred):\n",
    "    scipy.io.savemat('y_pred.mat', dict(y_pred=y_pred))\n",
    "    eng.interp_matlab(nargout=0)\n",
    "    y_sim = np.loadtxt(\"y_sim.dat\")\n",
    "    return y_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1aa7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_surrogate(X, Nt, model):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # cond\n",
    "    z_a = X[0:25]\n",
    "    z = torch.tensor(z_a)\n",
    "    z = z.unsqueeze(0)\n",
    "    z = z.float()\n",
    "    output = G.forward(z.cuda())\n",
    "    b1=torch.full(output[0][0].shape, 6).cuda()\n",
    "    b2=torch.full(output[0][0].shape, 2).cuda()\n",
    "    aa = torch.where(output[0] > 0, b1, b2)\n",
    "    cond = aa.squeeze().cpu().detach().numpy()\n",
    "    \n",
    "    \n",
    "    #\n",
    "    ss = X[25:]\n",
    "    Sx_id = 15\n",
    "    source = np.full((Nt,128,128), 0.0)\n",
    "    for j in range(Nt):\n",
    "        for ii in range(22,103):\n",
    "            Sy_id = ii\n",
    "            source[j, Sy_id, Sx_id] = ss[j]\n",
    "\n",
    "    x = np.full((1,3,128,128), 0.0)   \n",
    "    y = np.full( (Nt,2,128,128), 0.0) \n",
    "    y_i_1 = np.full((128,128), 0.0)   \n",
    "    for i in range(Nt):\n",
    "        x[0,0,:,:] = cond           \n",
    "        x[0,1,:,:] = source[i]      \n",
    "        x[0,2,:,:] = y_i_1          \n",
    "        x_tensor = (torch.FloatTensor(x)).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_hat = model(x_tensor)\n",
    "        y_hat = y_hat.data.cpu().numpy()\n",
    "        y[i] = y_hat\n",
    "        y_i_1 = y_hat[0,0,:,:]      \n",
    "    \n",
    "    y_pred = np.full( (Nt + 1,128,128), 0.0)\n",
    "    y_pred[:Nt] = y[:,0]   \n",
    "    y_pred[Nt]  = y[0,1]  \n",
    "\n",
    "    y_pre_obs = get_simv(y_pred)\n",
    "    \n",
    "    return y_pre_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96f5da0",
   "metadata": {},
   "source": [
    "## no surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##GMS\n",
    "x_para = scipy.io.loadmat('x1.mat')\n",
    "xf = x_para['x1']\n",
    "\n",
    "obs_model = scipy.io.loadmat('y1.mat')\n",
    "yf = obs_model['conc_head_Ne']\n",
    "\n",
    "\n",
    "scipy.io.savemat('xf.mat', {\"xf\": xf})\n",
    "scipy.io.savemat('yf.mat', {\"yf\": yf})\n",
    "xall = xf\n",
    "yall = yf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd80871a",
   "metadata": {},
   "source": [
    "## using surrogate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9892d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = scipy.io.loadmat('x1.mat')\n",
    "x1 = x1['x1']   \n",
    "Nobs = 15*8+15\n",
    "Nt = 8\n",
    "y1 = np.zeros((Nobs,x1.shape[1]))\n",
    "for i in range(x1.shape[1]):  # (x1, y1) are initial samples\n",
    "    y1[:,i] = run_surrogate(x1[:,i], Nt, model)\n",
    "scipy.io.savemat('y1.mat', dict(y1=y1))\n",
    "xf = x1\n",
    "yf = y1\n",
    "scipy.io.savemat('xf.mat', dict(xf=xf))  # Initial ensemble\n",
    "scipy.io.savemat('yf.mat', dict(yf=yf))\n",
    "xall = xf\n",
    "yall = yf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da322f7a",
   "metadata": {},
   "source": [
    "## Setting N_{t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef9d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Nt = 8\n",
    "Nobs = 15*8+15\n",
    "\n",
    "N_iter = 5\n",
    "for i in range(N_iter):\n",
    "    eng.ilues1(nargout=0)\n",
    "    xa = scipy.io.loadmat('xa.mat')\n",
    "    xa = xa['xa']\n",
    "    print('iter=',i+1)\n",
    "    \n",
    "    z_a = xa[0:25,:]\n",
    "    ss_a = xa[25:,:]\n",
    "    scipy.io.savemat('z_a.mat', {\"z_a\": z_a})\n",
    "    scipy.io.savemat('ss_a.mat', {\"ss_a\": ss_a})\n",
    "    \n",
    "    ya = np.zeros((Nobs, xa.shape[1]))\n",
    "    for j in range(xa.shape[1]):\n",
    "        ya[:,j] = run_surrogate(xa[:,j], Nt, model)\n",
    "    scipy.io.savemat('ya.mat', dict(ya=ya))\n",
    "    \n",
    "    \n",
    "    eng.update_samples(nargout=0) \n",
    "    xa = scipy.io.loadmat('xa.mat') \n",
    "    ya = scipy.io.loadmat('ya.mat')\n",
    "    xa = xa['xa']\n",
    "    ya = ya['ya']\n",
    "    \n",
    "    xall = np.concatenate((xall,xa),axis=1)\n",
    "    yall = np.concatenate((yall,ya),axis=1)\n",
    "scipy.io.savemat('results.mat', {\"xall\": xall,\"yall\":yall})  # save results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
